{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"..\")\n",
    "\n",
    "from utils import data as data_utils\n",
    "import torch_geometric as pyg\n",
    "from utils import ZincWithRDKit\n",
    "from datasets import DatasetDict, load_from_disk, IterableDataset\n",
    "from os.path import join\n",
    "import subprocess\n",
    "from utils import graphormer_data_collator_improved as graphormer_collator_utils\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "data_dir = \"./data\""
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/alexander/miniconda3/envs/pgt_hug/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#collator = graphormer_collator_utils.GraphormerDataCollator()\n",
    "#dataset_path =  \"/home/alexander/temp/ZINC/processed/arrow\"\n",
    "dataset_path =  \"data/pcqm4mv2/processed/arrow\"\n",
    "#dataset_path =  \"data/ZINC/processed/arrow_processed\"\n",
    "dataset = load_from_disk(\n",
    "    dataset_path, keep_in_memory=False\n",
    ")\n",
    "if isinstance(dataset, DatasetDict):\n",
    "    dataset = dataset[\"train\"]\n",
    "\n",
    "\n",
    "dataset.cleanup_cache_files()\n",
    "dataset_size = len(dataset)\n",
    "tot_batches = 1000\n",
    "batch_size = 256\n",
    "\n",
    "#dataset = dataset.shuffle()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "dataset[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'edge_attr': [[12, 0, 1],\n",
       "  [12, 0, 1],\n",
       "  [12, 0, 1],\n",
       "  [12, 0, 1],\n",
       "  [12, 0, 1],\n",
       "  [12, 0, 1],\n",
       "  [12, 0, 1],\n",
       "  [12, 0, 1],\n",
       "  [12, 0, 1],\n",
       "  [12, 0, 1],\n",
       "  [12, 0, 1],\n",
       "  [12, 0, 1],\n",
       "  [1, 0, 0],\n",
       "  [1, 0, 0],\n",
       "  [12, 0, 1],\n",
       "  [12, 0, 1],\n",
       "  [12, 0, 1],\n",
       "  [12, 0, 1],\n",
       "  [1, 0, 0],\n",
       "  [1, 0, 0],\n",
       "  [12, 0, 1],\n",
       "  [12, 0, 1],\n",
       "  [12, 0, 1],\n",
       "  [12, 0, 1],\n",
       "  [1, 0, 0],\n",
       "  [1, 0, 0],\n",
       "  [1, 0, 0],\n",
       "  [1, 0, 0],\n",
       "  [1, 0, 0],\n",
       "  [1, 0, 0],\n",
       "  [1, 0, 1],\n",
       "  [1, 0, 1],\n",
       "  [2, 0, 1],\n",
       "  [2, 0, 1],\n",
       "  [12, 0, 1],\n",
       "  [12, 0, 1],\n",
       "  [12, 0, 1],\n",
       "  [12, 0, 1],\n",
       "  [1, 0, 1],\n",
       "  [1, 0, 1]],\n",
       " 'node_feat': [[6, 0, 4, 5, 3, 0, 4, 0, 0],\n",
       "  [6, 0, 3, 5, 1, 0, 3, 1, 1],\n",
       "  [6, 0, 3, 5, 1, 0, 3, 1, 1],\n",
       "  [6, 0, 3, 5, 1, 0, 3, 1, 1],\n",
       "  [6, 0, 3, 5, 1, 0, 3, 1, 1],\n",
       "  [6, 0, 3, 5, 1, 0, 3, 1, 1],\n",
       "  [6, 0, 3, 5, 1, 0, 3, 1, 1],\n",
       "  [6, 0, 3, 5, 1, 1, 4, 0, 1],\n",
       "  [6, 0, 3, 5, 1, 0, 3, 1, 1],\n",
       "  [6, 0, 3, 5, 0, 0, 3, 1, 1],\n",
       "  [6, 0, 3, 5, 0, 0, 3, 1, 1],\n",
       "  [6, 0, 3, 5, 0, 0, 3, 1, 1],\n",
       "  [6, 1, 4, 5, 1, 0, 4, 0, 1],\n",
       "  [6, 0, 3, 5, 0, 0, 3, 1, 1],\n",
       "  [6, 0, 3, 5, 0, 0, 3, 0, 1],\n",
       "  [7, 0, 2, 5, 0, 0, 3, 1, 1],\n",
       "  [7, 0, 2, 5, 0, 1, 3, 0, 1],\n",
       "  [8, 0, 1, 5, 0, 0, 3, 0, 0]],\n",
       " 'smiles': 'Cc1ccc([C@H]2[CH]c3cnccc3[N]C2=O)cc1',\n",
       " 'num_nodes': 18,\n",
       " 'pos': [[4.9919, -5.2514, 4.0126],\n",
       "  [6.1051, -3.0257, 3.52],\n",
       "  [4.5521, -3.9001, 1.914],\n",
       "  [6.3372, -1.9217, 2.7029],\n",
       "  [4.7751, -2.7953, 1.0929],\n",
       "  [2.8586, 1.2252, -1.7853],\n",
       "  [2.8118, 0.8707, -3.0956],\n",
       "  [5.789, -0.835, -0.8455],\n",
       "  [4.6658, -0.476, -3.0127],\n",
       "  [5.215, -4.0391, 3.1392],\n",
       "  [5.677, -1.7955, 1.4745],\n",
       "  [4.8499, -0.2104, -1.5946],\n",
       "  [5.9121, -0.5519, 0.613],\n",
       "  [3.9134, 0.7241, -0.934],\n",
       "  [5.0405, 0.6404, 1.1008],\n",
       "  [3.716, 0.0207, -3.7371],\n",
       "  [3.9796, 1.1019, 0.3172],\n",
       "  [5.2985, 1.1457, 2.1772]],\n",
       " 'edge_index': [[2,\n",
       "   9,\n",
       "   3,\n",
       "   1,\n",
       "   4,\n",
       "   10,\n",
       "   4,\n",
       "   2,\n",
       "   5,\n",
       "   13,\n",
       "   6,\n",
       "   5,\n",
       "   7,\n",
       "   12,\n",
       "   8,\n",
       "   11,\n",
       "   9,\n",
       "   1,\n",
       "   9,\n",
       "   0,\n",
       "   10,\n",
       "   3,\n",
       "   11,\n",
       "   13,\n",
       "   11,\n",
       "   7,\n",
       "   12,\n",
       "   14,\n",
       "   12,\n",
       "   10,\n",
       "   13,\n",
       "   16,\n",
       "   14,\n",
       "   17,\n",
       "   15,\n",
       "   6,\n",
       "   15,\n",
       "   8,\n",
       "   16,\n",
       "   14],\n",
       "  [9,\n",
       "   2,\n",
       "   1,\n",
       "   3,\n",
       "   10,\n",
       "   4,\n",
       "   2,\n",
       "   4,\n",
       "   13,\n",
       "   5,\n",
       "   5,\n",
       "   6,\n",
       "   12,\n",
       "   7,\n",
       "   11,\n",
       "   8,\n",
       "   1,\n",
       "   9,\n",
       "   0,\n",
       "   9,\n",
       "   3,\n",
       "   10,\n",
       "   13,\n",
       "   11,\n",
       "   7,\n",
       "   11,\n",
       "   14,\n",
       "   12,\n",
       "   10,\n",
       "   12,\n",
       "   16,\n",
       "   13,\n",
       "   17,\n",
       "   14,\n",
       "   6,\n",
       "   15,\n",
       "   8,\n",
       "   15,\n",
       "   14,\n",
       "   16]],\n",
       " 'name': '/Volumes/PubChemQCDataBaseWork/pubchemqc2017database/xyz/00000000_00009999/0.xyz',\n",
       " 'id': 0}"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "dataset[0][\"node_feat\"]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[6, 0, 4, 5, 3, 0, 4, 0, 0],\n",
       " [6, 0, 3, 5, 1, 0, 3, 1, 1],\n",
       " [6, 0, 3, 5, 1, 0, 3, 1, 1],\n",
       " [6, 0, 3, 5, 1, 0, 3, 1, 1],\n",
       " [6, 0, 3, 5, 1, 0, 3, 1, 1],\n",
       " [6, 0, 3, 5, 1, 0, 3, 1, 1],\n",
       " [6, 0, 3, 5, 1, 0, 3, 1, 1],\n",
       " [6, 0, 3, 5, 1, 1, 4, 0, 1],\n",
       " [6, 0, 3, 5, 1, 0, 3, 1, 1],\n",
       " [6, 0, 3, 5, 0, 0, 3, 1, 1],\n",
       " [6, 0, 3, 5, 0, 0, 3, 1, 1],\n",
       " [6, 0, 3, 5, 0, 0, 3, 1, 1],\n",
       " [6, 1, 4, 5, 1, 0, 4, 0, 1],\n",
       " [6, 0, 3, 5, 0, 0, 3, 1, 1],\n",
       " [6, 0, 3, 5, 0, 0, 3, 0, 1],\n",
       " [7, 0, 2, 5, 0, 0, 3, 1, 1],\n",
       " [7, 0, 2, 5, 0, 1, 3, 0, 1],\n",
       " [8, 0, 1, 5, 0, 0, 3, 0, 0]]"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "max(dataset[0][\"node_feat\"])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[8, 0, 1, 5, 0, 0, 3, 0, 0]"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "max(max(dataset[0][\"node_feat\"]))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "true_max = 0\n",
    "for i in tqdm(dataset_size):\n",
    "    sample_max = max(max(dataset[i][\"node_feat\"]))\n",
    "    if sample_max > true_max:\n",
    "        true_max = sample_max\n",
    "        print(true_max, i)\n",
    "    #samples.append(dataset[i + 1000000])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/92669E5D669E4241/pretrained-graph-transformer/scripts/ipy_transform_data.py\u001b[0m in \u001b[0;36mline 3\n\u001b[1;32m      <a href='file:///mnt/92669E5D669E4241/pretrained-graph-transformer/scripts/ipy_transform_data.py?line=277'>278</a>\u001b[0m \u001b[39m#%% only loading\u001b[39;00m\n\u001b[1;32m      <a href='file:///mnt/92669E5D669E4241/pretrained-graph-transformer/scripts/ipy_transform_data.py?line=278'>279</a>\u001b[0m true_max \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m----> <a href='file:///mnt/92669E5D669E4241/pretrained-graph-transformer/scripts/ipy_transform_data.py?line=279'>280</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(dataset_size):\n\u001b[1;32m      <a href='file:///mnt/92669E5D669E4241/pretrained-graph-transformer/scripts/ipy_transform_data.py?line=280'>281</a>\u001b[0m     sample_max \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39mmax\u001b[39m(dataset[i][\u001b[39m\"\u001b[39m\u001b[39mnode_feat\u001b[39m\u001b[39m\"\u001b[39m]))\n\u001b[1;32m      <a href='file:///mnt/92669E5D669E4241/pretrained-graph-transformer/scripts/ipy_transform_data.py?line=281'>282</a>\u001b[0m     \u001b[39mif\u001b[39;00m sample_max \u001b[39m>\u001b[39m true_max:\n",
      "File \u001b[0;32m~/miniconda3/envs/pgt_hug/lib/python3.10/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///home/alexander/miniconda3/envs/pgt_hug/lib/python3.10/site-packages/tqdm/std.py?line=1174'>1175</a>\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   <a href='file:///home/alexander/miniconda3/envs/pgt_hug/lib/python3.10/site-packages/tqdm/std.py?line=1176'>1177</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///home/alexander/miniconda3/envs/pgt_hug/lib/python3.10/site-packages/tqdm/std.py?line=1177'>1178</a>\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   <a href='file:///home/alexander/miniconda3/envs/pgt_hug/lib/python3.10/site-packages/tqdm/std.py?line=1178'>1179</a>\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   <a href='file:///home/alexander/miniconda3/envs/pgt_hug/lib/python3.10/site-packages/tqdm/std.py?line=1179'>1180</a>\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/alexander/miniconda3/envs/pgt_hug/lib/python3.10/site-packages/tqdm/std.py?line=1180'>1181</a>\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "true_max = 0\n",
    "for i in tqdm(range(dataset_size)):\n",
    "    sample_max = max(max(dataset[i][\"node_feat\"]))\n",
    "    if sample_max > true_max:\n",
    "        true_max = sample_max\n",
    "        print(true_max, i)\n",
    "    #samples.append(dataset[i + 1000000])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 503/3378606 [00:00<21:16, 2646.58it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "8 0\n",
      "9 3\n",
      "17 4\n",
      "35 99\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 3378606/3378606 [17:58<00:00, 3134.02it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "#collator = graphormer_collator_utils.GraphormerDataCollator()\n",
    "#dataset_path =  \"/home/alexander/temp/ZINC/processed/arrow\"\n",
    "dataset_path =  \"data/tox21_original/processed/arrow\"\n",
    "#dataset_path =  \"data/ZINC/processed/arrow_processed\"\n",
    "dataset = load_from_disk(\n",
    "    dataset_path, keep_in_memory=False\n",
    ")\n",
    "if isinstance(dataset, DatasetDict):\n",
    "    dataset = dataset[\"train\"]\n",
    "\n",
    "\n",
    "dataset.cleanup_cache_files()\n",
    "dataset_size = len(dataset)\n",
    "tot_batches = 1000\n",
    "batch_size = 256\n",
    "\n",
    "#dataset = dataset.shuffle()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "true_max = 0\n",
    "for i in tqdm(range(dataset_size)):\n",
    "    sample_max = max(max(dataset[i][\"node_feat\"]))\n",
    "    if sample_max > true_max:\n",
    "        true_max = sample_max\n",
    "        print(true_max, i)\n",
    "    #samples.append(dataset[i + 1000000])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 20%|██        | 131/645 [00:00<00:01, 313.89it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "8 0\n",
      "35 1\n",
      "53 24\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 645/645 [00:01<00:00, 627.60it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "80 498\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "dataset_size"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "645"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "dataset = load_from_disk(\n",
    "    dataset_path, keep_in_memory=False\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "dataset"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['edge_attr', 'node_feat', 'smiles', 'num_nodes', 'pos', 'edge_index', 'name', 'id', 'target'],\n",
       "    num_rows: 645\n",
       "})"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "#collator = graphormer_collator_utils.GraphormerDataCollator()\n",
    "#dataset_path =  \"/home/alexander/temp/ZINC/processed/arrow\"\n",
    "dataset_path =  \"data/tox21_original/processed/arrow\"\n",
    "#dataset_path =  \"data/ZINC/processed/arrow_processed\"\n",
    "dataset = DatasetDict.load_from_disk(\n",
    "    dataset_path, keep_in_memory=False\n",
    ")\n",
    "if isinstance(dataset, DatasetDict):\n",
    "    dataset = dataset[\"train\"]\n",
    "\n",
    "\n",
    "dataset.cleanup_cache_files()\n",
    "dataset_size = len(dataset)\n",
    "tot_batches = 1000\n",
    "batch_size = 256\n",
    "\n",
    "#dataset = dataset.shuffle()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "dataset"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['edge_attr', 'node_feat', 'smiles', 'num_nodes', 'pos', 'edge_index', 'name', 'id', 'target'],\n",
       "    num_rows: 11758\n",
       "})"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "true_max = 0\n",
    "for i in tqdm(range(dataset_size)):\n",
    "    sample_max = max(max(dataset[i][\"node_feat\"]))\n",
    "    if sample_max > true_max:\n",
    "        true_max = sample_max\n",
    "        print(true_max, i)\n",
    "    #samples.append(dataset[i + 1000000])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  2%|▏         | 230/11758 [00:00<00:08, 1315.59it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "17 0\n",
      "35 1\n",
      "80 6\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  7%|▋         | 870/11758 [00:00<00:05, 2012.81it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "83 617\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 11758/11758 [00:04<00:00, 2556.41it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "dataset = DatasetDict.load_from_disk(\n",
    "    dataset_path, keep_in_memory=False\n",
    ")\n",
    ""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "dataset"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['edge_attr', 'node_feat', 'smiles', 'num_nodes', 'pos', 'edge_index', 'name', 'id', 'target'],\n",
       "        num_rows: 11758\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['edge_attr', 'node_feat', 'smiles', 'num_nodes', 'pos', 'edge_index', 'name', 'id', 'target'],\n",
       "        num_rows: 295\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['edge_attr', 'node_feat', 'smiles', 'num_nodes', 'pos', 'edge_index', 'name', 'id', 'target'],\n",
       "        num_rows: 645\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "#collator = graphormer_collator_utils.GraphormerDataCollator()\n",
    "#dataset_path =  \"/home/alexander/temp/ZINC/processed/arrow\"\n",
    "dataset_path =  \"data/tox21_original/processed/arrow\"\n",
    "#dataset_path =  \"data/ZINC/processed/arrow_processed\"\n",
    "dataset = DatasetDict.load_from_disk(\n",
    "    dataset_path, keep_in_memory=False\n",
    ")\n",
    "if isinstance(dataset, DatasetDict):\n",
    "    dataset = dataset[\"validation\"]\n",
    "\n",
    "\n",
    "dataset.cleanup_cache_files()\n",
    "dataset_size = len(dataset)\n",
    "tot_batches = 1000\n",
    "batch_size = 256\n",
    "\n",
    "#dataset = dataset.shuffle()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "true_max = 0\n",
    "for i in tqdm(range(dataset_size)):\n",
    "    sample_max = max(max(dataset[i][\"node_feat\"]))\n",
    "    if sample_max > true_max:\n",
    "        true_max = sample_max\n",
    "        print(true_max, i)\n",
    "    #samples.append(dataset[i + 1000000])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 295/295 [00:00<00:00, 2142.76it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "8 0\n",
      "17 2\n",
      "35 3\n",
      "44 13\n",
      "53 29\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "#collator = graphormer_collator_utils.GraphormerDataCollator()\n",
    "#dataset_path =  \"/home/alexander/temp/ZINC/processed/arrow\"\n",
    "dataset_path =  \"data/tox21/processed/arrow\"\n",
    "#dataset_path =  \"data/ZINC/processed/arrow_processed\"\n",
    "dataset = load_from_disk(\n",
    "    dataset_path, keep_in_memory=False\n",
    ")\n",
    "if isinstance(dataset, DatasetDict):\n",
    "    dataset = dataset[\"validation\"]\n",
    "\n",
    "\n",
    "dataset.cleanup_cache_files()\n",
    "dataset_size = len(dataset)\n",
    "tot_batches = 1000\n",
    "batch_size = 256\n",
    "\n",
    "#dataset = dataset.shuffle()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "true_max = 0\n",
    "for i in tqdm(range(dataset_size)):\n",
    "    sample_max = max(max(dataset[i][\"node_feat\"]))\n",
    "    if sample_max > true_max:\n",
    "        true_max = sample_max\n",
    "        print(true_max, i)\n",
    "    #samples.append(dataset[i + 1000000])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  6%|▌         | 445/7555 [00:00<00:02, 2373.14it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "16 0\n",
      "17 6\n",
      "53 7\n",
      "80 240\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 16%|█▋        | 1231/7555 [00:00<00:02, 2117.74it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "81 951\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 32%|███▏      | 2394/7555 [00:00<00:01, 2656.57it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "82 1870\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 40%|███▉      | 3001/7555 [00:01<00:01, 2639.17it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "83 2630\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 7555/7555 [00:02<00:00, 2729.28it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "dataset[0][\"node_feat\"]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[6, 0, 4, 5, 3, 0, 4, 0, 0],\n",
       " [6, 0, 4, 5, 2, 0, 4, 0, 0],\n",
       " [8, 0, 2, 5, 0, 0, 3, 0, 0],\n",
       " [6, 0, 3, 5, 0, 0, 3, 1, 1],\n",
       " [6, 0, 3, 5, 1, 0, 3, 1, 1],\n",
       " [6, 0, 3, 5, 1, 0, 3, 1, 1],\n",
       " [6, 0, 3, 5, 0, 0, 3, 1, 1],\n",
       " [7, 0, 2, 5, 0, 0, 3, 1, 1],\n",
       " [6, 0, 3, 5, 0, 0, 3, 1, 1],\n",
       " [16, 0, 4, 5, 0, 0, 4, 0, 0],\n",
       " [7, 0, 3, 5, 2, 0, 4, 0, 0],\n",
       " [8, 0, 1, 5, 0, 0, 3, 0, 0],\n",
       " [8, 0, 1, 5, 0, 0, 3, 0, 0],\n",
       " [16, 0, 2, 5, 0, 0, 3, 1, 1],\n",
       " [6, 0, 3, 5, 0, 0, 3, 1, 1],\n",
       " [6, 0, 3, 5, 1, 0, 3, 1, 1]]"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "#collator = graphormer_collator_utils.GraphormerDataCollator()\n",
    "#dataset_path =  \"/home/alexander/temp/ZINC/processed/arrow\"\n",
    "dataset_path =  \"data/ZINC/processed/arrow\"\n",
    "#dataset_path =  \"data/ZINC/processed/arrow_processed\"\n",
    "dataset = DatasetDict.load_from_disk(\n",
    "    dataset_path, keep_in_memory=False\n",
    ")\n",
    "if isinstance(dataset, DatasetDict):\n",
    "    dataset = dataset[\"validation\"]\n",
    "\n",
    "\n",
    "dataset.cleanup_cache_files()\n",
    "dataset_size = len(dataset)\n",
    "tot_batches = 1000\n",
    "batch_size = 256\n",
    "\n",
    "#dataset = dataset.shuffle()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "true_max = 0\n",
    "for i in tqdm(range(dataset_size)):\n",
    "    sample_max = max(max(dataset[i][\"node_feat\"]))\n",
    "    if sample_max > true_max:\n",
    "        true_max = sample_max\n",
    "        print(true_max, i)\n",
    "    #samples.append(dataset[i + 1000000])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 31%|███       | 310/1000 [00:00<00:00, 1686.67it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "16 0\n",
      "17 2\n",
      "53 36\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 2129.74it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "#collator = graphormer_collator_utils.GraphormerDataCollator()\n",
    "#dataset_path =  \"/home/alexander/temp/ZINC/processed/arrow\"\n",
    "dataset_path =  \"data/ZINC/processed/arrow\"\n",
    "#dataset_path =  \"data/ZINC/processed/arrow_processed\"\n",
    "dataset = DatasetDict.load_from_disk(\n",
    "    dataset_path, keep_in_memory=False\n",
    ")\n",
    "if isinstance(dataset, DatasetDict):\n",
    "    dataset = dataset[\"test\"]\n",
    "\n",
    "\n",
    "dataset.cleanup_cache_files()\n",
    "dataset_size = len(dataset)\n",
    "tot_batches = 1000\n",
    "batch_size = 256\n",
    "\n",
    "#dataset = dataset.shuffle()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "true_max = 0\n",
    "for i in tqdm(range(dataset_size)):\n",
    "    sample_max = max(max(dataset[i][\"node_feat\"]))\n",
    "    if sample_max > true_max:\n",
    "        true_max = sample_max\n",
    "        print(true_max, i)\n",
    "    #samples.append(dataset[i + 1000000])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 78%|███████▊  | 785/1000 [00:00<00:00, 1491.85it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "17 0\n",
      "53 6\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1140.04it/s]\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "#collator = graphormer_collator_utils.GraphormerDataCollator()\n",
    "#dataset_path =  \"/home/alexander/temp/ZINC/processed/arrow\"\n",
    "dataset_path =  \"data/ZINC/processed/arrow\"\n",
    "#dataset_path =  \"data/ZINC/processed/arrow_processed\"\n",
    "dataset = DatasetDict.load_from_disk(\n",
    "    dataset_path, keep_in_memory=False\n",
    ")\n",
    "if isinstance(dataset, DatasetDict):\n",
    "    dataset = dataset[\"train\"]\n",
    "\n",
    "\n",
    "dataset.cleanup_cache_files()\n",
    "dataset_size = len(dataset)\n",
    "tot_batches = 1000\n",
    "batch_size = 256\n",
    "\n",
    "#dataset = dataset.shuffle()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "true_max = 0\n",
    "for i in tqdm(range(dataset_size)):\n",
    "    sample_max = max(max(dataset[i][\"node_feat\"]))\n",
    "    if sample_max > true_max:\n",
    "        true_max = sample_max\n",
    "        print(true_max, i)\n",
    "    #samples.append(dataset[i + 1000000])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  4%|▍         | 403/10000 [00:00<00:11, 820.56it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "16 0\n",
      "17 2\n",
      "35 24\n",
      "53 123\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 10000/10000 [00:04<00:00, 2130.08it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "#collator = graphormer_collator_utils.GraphormerDataCollator()\n",
    "#dataset_path =  \"/home/alexander/temp/ZINC/processed/arrow\"\n",
    "dataset_path =  \"data/qm9/processed/arrow\"\n",
    "#dataset_path =  \"data/ZINC/processed/arrow_processed\"\n",
    "dataset = load_from_disk(\n",
    "    dataset_path, keep_in_memory=False\n",
    ")\n",
    "if isinstance(dataset, DatasetDict):\n",
    "    dataset = dataset[\"train\"]\n",
    "\n",
    "\n",
    "dataset.cleanup_cache_files()\n",
    "dataset_size = len(dataset)\n",
    "tot_batches = 1000\n",
    "batch_size = 256\n",
    "\n",
    "#dataset = dataset.shuffle()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "true_max = 0\n",
    "for i in tqdm(range(dataset_size)):\n",
    "    sample_max = max(max(dataset[i][\"node_feat\"]))\n",
    "    if sample_max > true_max:\n",
    "        true_max = sample_max\n",
    "        print(true_max, i)\n",
    "    #samples.append(dataset[i + 1000000])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  1%|          | 976/133247 [00:00<00:26, 4990.71it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6 0\n",
      "7 1\n",
      "8 2\n",
      "9 183\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 133247/133247 [00:33<00:00, 4018.66it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "dataset"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['edge_attr', 'node_feat', 'smiles', 'num_nodes', 'pos', 'edge_index', 'name', 'id', 'target'],\n",
       "    num_rows: 133247\n",
       "})"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "dataset[0][\"smiles\"]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'C'"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "dataset[12312][\"smiles\"]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'CC1C=CCCC1C'"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "#collator = graphormer_collator_utils.GraphormerDataCollator()\n",
    "#dataset_path =  \"/home/alexander/temp/ZINC/processed/arrow\"\n",
    "dataset_path =  \"data/pcba/processed/arrow\"\n",
    "#dataset_path =  \"data/ZINC/processed/arrow_processed\"\n",
    "dataset = load_from_disk(\n",
    "    dataset_path, keep_in_memory=False\n",
    ")\n",
    "if isinstance(dataset, DatasetDict):\n",
    "    dataset = dataset[\"train\"]\n",
    "\n",
    "\n",
    "dataset.cleanup_cache_files()\n",
    "dataset_size = len(dataset)\n",
    "tot_batches = 1000\n",
    "batch_size = 256\n",
    "\n",
    "#dataset = dataset.shuffle()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "true_max = 0\n",
    "for i in tqdm(range(dataset_size)):\n",
    "    sample_max = max(max(dataset[i][\"node_feat\"]))\n",
    "    if sample_max > true_max:\n",
    "        true_max = sample_max\n",
    "        print(true_max, i)\n",
    "    #samples.append(dataset[i + 1000000])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 439/437929 [00:00<03:12, 2272.76it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "8 0\n",
      "17 1\n",
      "35 13\n",
      "53 565\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  1%|▏         | 6280/437929 [00:02<02:53, 2481.28it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "78 6005\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  3%|▎         | 13534/437929 [00:05<02:50, 2487.88it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "80 13059\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  8%|▊         | 35197/437929 [00:14<02:53, 2321.17it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "83 34821\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 437929/437929 [03:15<00:00, 2240.69it/s]\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 4
 }
}